{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from algorithms import steepest_descent, conjugate_gradient, secant, Finite_Difference, armijo\n",
    "from cost_functions import V_a, gradV_a, V_b, gradV_b\n",
    "from numpy.linalg import norm, eig\n",
    "from functools import partial\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lagrange_newton(x0, \n",
    "                    cost_function, \n",
    "                    gradient_function = None,\n",
    "                    hessian = None,\n",
    "                    equality_constraints = [], \n",
    "                    inequality_constraints = [],\n",
    "                    threshold=1e-8,\n",
    "                    h = 1e-8,\n",
    "                    fd_method = 'forward',\n",
    "                    log = False,\n",
    "                    track_history = False):\n",
    "\n",
    "    fd = Finite_Difference(cost_function, fd_method, h)\n",
    "    if hessian is None: \n",
    "        hessian_ = fd.hessian\n",
    "    else: \n",
    "        hessian_ = hessian\n",
    "    if gradient_function is None:\n",
    "        gradV = fd.estimate_gradient\n",
    "    else: \n",
    "        gradV = gradient_function\n",
    "\n",
    "    x_history, V_history = [], []\n",
    "\n",
    "    num_ec = len(equality_constraints)\n",
    "    num_ic = len(inequality_constraints)\n",
    "    num_c = num_ec + num_ic\n",
    "    lambd = np.zeros((num_c, 1))\n",
    "    x = x0\n",
    "\n",
    "\n",
    "    def W(x, lmb):\n",
    "        lambda_eq = lmb[:num_ec, :]\n",
    "        lambda_iq = lmb[num_ec:num_c, :]\n",
    "        hess = hessian_(x)\n",
    "        hess_eq = 0\n",
    "        for i,ec in enumerate(equality_constraints):\n",
    "            hess_eq -=  Finite_Difference(ec, fd_method).hessian(x) * lambda_eq[i] \n",
    "        hess_iq = 0\n",
    "        for i,ic in enumerate(inequality_constraints):\n",
    "            hess_iq -=  Finite_Difference(ic, fd_method).hessian(x) * lambda_iq[i] \n",
    "        return hess + hess_eq + hess_iq\n",
    "\n",
    "    def A(x):\n",
    "        equality_grads = [Finite_Difference(ec, fd_method).estimate_gradient(x) \n",
    "                                                for ec in equality_constraints]\n",
    "        inequality_grads = [Finite_Difference(ic, fd_method).estimate_gradient(x) \n",
    "                                                for ic in inequality_constraints]\n",
    "        grads = equality_grads + inequality_grads\n",
    "        return np.array(grads).squeeze()\n",
    "\n",
    "    dx = 1e12\n",
    "    while True:\n",
    "\n",
    "        if norm(dx) <= threshold: \n",
    "            break\n",
    "        \n",
    "        inequality_cost = [ic(x) for ic in inequality_constraints]\n",
    "        equality_cost = [ec(x) for ec in equality_constraints]\n",
    "\n",
    "        KKT = np.block([[W(x, lambd), -A(x).T],\n",
    "                        [-A(x), np.zeros((num_c, num_c))]])\n",
    "        if num_c == num_ic:\n",
    "            funcs = np.block([[-gradV(x) + A(x) @lambd], \n",
    "                      [np.array(inequality_cost)]])\n",
    "        elif num_c == num_ec:\n",
    "            funcs = np.block([[-gradV(x) + A(x) @lambd], \n",
    "                    [np.array(equality_cost)]])\n",
    "        else:\n",
    "            funcs = np.block([[-gradV(x) + A(x) @lambd], \n",
    "                          [np.array(equality_cost)],\n",
    "                          [np.array(inequality_cost)]])\n",
    "        solution, _, _, _ = np.linalg.lstsq(KKT, funcs, rcond=1e-5)\n",
    "        x0 = x\n",
    "        x = x + solution[:x.shape[0], :]\n",
    "        lambd = lambd + solution[x.shape[0]:, :]\n",
    "\n",
    "        minimum = cost_function(x)\n",
    "        x_history.append(x), V_history.append(minimum)\n",
    "        dx = x - x0\n",
    "        \n",
    "        #track results\n",
    "        if log: \n",
    "            print(f'x = {x}, V(x) = {minimum:.5f}')\n",
    "    \n",
    "    if track_history:\n",
    "        return x, minimum, x_history, V_history\n",
    "    else: \n",
    "        return x, minimum\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.61803399],\n",
       "        [0.78615138]]),\n",
       " array([-1.59581463]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def V_1(x):\n",
    "    return -1*(np.abs(x[0]-1) + np.abs(x[1]-2))\n",
    "\n",
    "def h1_1(x):\n",
    "    return x[0]-x[1]**2\n",
    "\n",
    "def h2_1(x):\n",
    "    return x[0]**2 + x[1]**2 - 1\n",
    "\n",
    "\n",
    "x0 = np.random.uniform(low=-2, high=2, size=(1,2)).T\n",
    "x0 = np.array([[0.5], [0.5]])\n",
    "\n",
    "equality_constraints = [h1_1]\n",
    "inequality_constraints = [h2_1]\n",
    "\n",
    "x, minimum = lagrange_newton(x0,\n",
    "                    cost_function = V_1, \n",
    "                    inequality_constraints = inequality_constraints,\n",
    "                    equality_constraints = equality_constraints)\n",
    "x, minimum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.61803399],\n",
       "        [-0.61803399]]),\n",
       " array([0.38196601]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def v(x):\n",
    "   return  -x[0]*x[1]\n",
    "\n",
    "def h1(x):\n",
    "    return -x[0]-x[1]**2 + 1\n",
    "\n",
    "def h2(x):\n",
    "    return x[0] + x[1]\n",
    "\n",
    "def v1(x):\n",
    "   return  -x[0]*x[1]\n",
    "\n",
    "x0 = np.random.uniform(low=-2, high=2, size=(1,2)).T\n",
    "x0 = np.array([[-0.5], [0]])\n",
    "\n",
    "\n",
    "\n",
    "inequality_constraints = [h1, h2]\n",
    "\n",
    "x, minimum = lagrange_newton(x0,\n",
    "                    cost_function = v, \n",
    "                    inequality_constraints = inequality_constraints)\n",
    "x, minimum \n",
    "\n",
    "#0.67, -0.57\n",
    "#0.385"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        ],\n",
       "        [1.73205081]]),\n",
       " array([-1.73205081]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def V_3(x):\n",
    "    return np.log(x[0]) - x[1]\n",
    "\n",
    "def h1_3(x):\n",
    "    return x[0]-1\n",
    "\n",
    "def h2_3(x):\n",
    "    return x[0]**2 + x[1]**2 - 4\n",
    "\n",
    "\n",
    "x0 = np.array([[2.], [1.5]])\n",
    "\n",
    "\n",
    "x, minimum = lagrange_newton(x0,\n",
    "                    cost_function = V_3, \n",
    "                    equality_constraints = [h2_3], \n",
    "                    inequality_constraints = [h1_3])\n",
    "x, minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e730323216fec8a00495a18d5e26a9184315a136cb5e6ee6f99d5a78808c1dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
